{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    " \n",
    "We consider the problem of predicting health risk of subjects from personal data and habits. We first use for this task a decision tree\n",
    "\n",
    "![](tree.png)\n",
    "\n",
    "adapted from the webpage http://www.refactorthis.net/post/2013/04/10/Machine-Learning-tutorial-How-to-create-a-decision-tree-in-RapidMiner-using-the-Titanic-passenger-data-set.aspx. For this exercise sheet, we are required to use only pure Python, and to not import any module, including numpy. In exercise sheet 2, the nearest neighbor part of this exercise sheet will be revisited with numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm: Classifying a single instance\n",
    "\n",
    "Create a function that takes as input a tuple containing values for attributes, and computes the output of the decision tree. Should return a class.\n",
    "Test the function on the tuple `('yes', 31, 'good')`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f3e47f689550d7323b8965c76a70298d",
     "grade": false,
     "grade_id": "cell-b66d7278bc313c94",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def decision(x):\n",
    "      \n",
    "    # Input validation\n",
    "    assert type(x) == tuple, \"Argument is not a tuple\"\n",
    "    assert len(x) == 3, \"Arument must have 3 values\"\n",
    "    \n",
    "    # Divide values into 3 variables for a future operations\n",
    "    smoker, age, diet = x\n",
    "    \n",
    "    if smoker.lower() == \"yes\":\n",
    "        if age < 29.5:\n",
    "            return \"less\"\n",
    "        else:\n",
    "            return \"more\"\n",
    "    else:\n",
    "        if diet.lower() == \"good\":\n",
    "            return \"less\"\n",
    "        else:\n",
    "            return \"more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c0559abdef335108b9edbb4ea3011c4c",
     "grade": true,
     "grade_id": "cell-c31b80471db3132f",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "x = ('yes', 31, 'good')\n",
    "assert decision(x) == 'more'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm: Reading a data set\n",
    "The file `health-test.txt` contains several fictious records of personal data and habits.\n",
    "\n",
    "Read the file.Represent the dataset as a list of tuples. Assert the tuples have the same format as above. Extra note of the datatype of each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8217159008caa1db2f6649e3ed092d9f",
     "grade": false,
     "grade_id": "cell-c1a8bc4c0e4ccb26",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gettest():\n",
    "    \n",
    "    # Read the file\n",
    "    with open('health-test.txt', 'r') as f:\n",
    "        \n",
    "        data = list()\n",
    "        \n",
    "        for line in f:\n",
    "            # Split each line into different variables\n",
    "            smoker, age, diet = line[:-1].split(',')\n",
    "            \n",
    "            # Combine all variables into a tuple, with a certain types\n",
    "            observation = (str(smoker),int(age),str(diet))\n",
    "            \n",
    "            # Task: Make extra note of the datatype of each element\n",
    "            assert type(observation) == tuple\n",
    "            assert [type(x) for x in observation] == [str,int,str]\n",
    "            \n",
    "            # Add the observation to the data list\n",
    "            data.append(observation)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5a6c609343f9b1d4bb9e02d4cc0abc2e",
     "grade": true,
     "grade_id": "cell-4e1f7ad1e66b3121",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm: Classifying a data set\n",
    "\n",
    "Application of the decision tree to all points in the dataset, and return the ratio of them that are classified as class 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6a8ebad6d019805a1f317cd25c329cff",
     "grade": false,
     "grade_id": "cell-6703ef98e2b5c93b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_testset():\n",
    "    \n",
    "    prediction_list = list()\n",
    "    \n",
    "    for observation in gettest():\n",
    "        \n",
    "        # Apply Decision Tree to each observation \n",
    "        prediction = decision(observation)\n",
    "        \n",
    "        # Combine all predictions into one list\n",
    "        prediction_list.append(prediction)\n",
    "    \n",
    "    # Caculate a share of \"more\"  in the whole prediction list\n",
    "    ratio = prediction_list.count(\"more\")/len(prediction_list)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2cf754f1f4a98838c63a6840e15ae198",
     "grade": true,
     "grade_id": "cell-c13a0b23c9faba52",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm: Reading a train set\n",
    "\n",
    "Suppose that instead of relying on a fixed decision tree, we would like to use a data-driven approach where data points are classified based on a set of training observations manually labeled by experts. Such labeled dataset is available in the file `health-train.txt`. The first three columns have the same meaning than for `health-test.txt`, and the last column corresponds to the labels.\n",
    "The procedure reads this file and converts it into a list of pairs. The first element of each pair is a triplet of attributes, and the second element is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e6de29aa89d0457a5c0aeb5d7123a2ef",
     "grade": false,
     "grade_id": "cell-fc38ed11fee6fbeb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gettrain():\n",
    "    \n",
    "    # Read the file\n",
    "    with open('health-train.txt', 'r') as f:\n",
    "        \n",
    "        data = list()\n",
    "        \n",
    "        for line in f:\n",
    "            \n",
    "            # Split each line into different variables\n",
    "            smoker, age, diet, risk = line[:-1].split(',')\n",
    "            \n",
    "            # Combine all variables into a pair of tuple (with 3 values with certain types) and a target variable (as a str)\n",
    "            pair = [(str(smoker),int(age),str(diet)),str(risk)]\n",
    "            \n",
    "            # Add the pair to the data list\n",
    "            data.append(pair)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "925716f474f7b0e3a7892e1aebfa217e",
     "grade": true,
     "grade_id": "cell-a3d593f232e0403a",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Classifier: Distance function\n",
    "\n",
    "We consider the nearest neighbor algorithm that classifies test points following the label of the nearest neighbor in the training data. For this, we need to define a distance function between data points. We define it to be\n",
    "\n",
    "`d(a, b) = (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])`\n",
    "\n",
    "where `a` and `b` are two tuples corrsponding to the attributes of two data points. Write a function that retrieves for a test point the nearest neighbor in the training set, and classifies the test point accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "87751ef965d915307f761da8071a184f",
     "grade": false,
     "grade_id": "cell-671ea24ec8a11241",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def neighbor(x, trainset):\n",
    "\n",
    "    # Define distance function\n",
    "    distance_nnc = lambda a,b: (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])\n",
    "    \n",
    "    prediction = list()\n",
    "    \n",
    "    # Extract each pair from the train set\n",
    "    for observation in trainset:\n",
    "        \n",
    "        # Compute the distance\n",
    "        current_distance = distance_nnc(x,observation[0])\n",
    "        \n",
    "        # Check if the current distance lower then the previous one\n",
    "        if len(prediction) == 0 or current_distance < prediction[0]:\n",
    "            \n",
    "            # Update prediction\n",
    "            prediction = [current_distance,observation[1]]\n",
    "            \n",
    "    return prediction[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "528146e447a25173480343d5fb7fd585",
     "grade": true,
     "grade_id": "cell-a36122337853f195",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicaion of both the decision tree and nearest neighbor classifiers on the test set, and return the list of data point(s) for which the two classifiers disagree, and with which probability it happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d26e5477527236f7db5c7cb6f8589c3a",
     "grade": false,
     "grade_id": "cell-8dbf7da153f3d797",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compare():\n",
    "    \n",
    "    # Get train and test data sets\n",
    "    train = gettrain()\n",
    "    test = gettest()\n",
    "    \n",
    "    Xdisagree = []\n",
    "    \n",
    "    for x in test:\n",
    "        \n",
    "        # Apply Decision Tree\n",
    "        dt_prediction = decision(x)\n",
    "        \n",
    "        # Apply Nearest Neighbor Classifiers\n",
    "        nnc_prediction = neighbor(x, train)\n",
    "        \n",
    "        # If disagreement - add x to Xdisagree\n",
    "        if dt_prediction != nnc_prediction: \n",
    "            Xdisagree.append(x)\n",
    "        \n",
    "        probability = len(Xdisagree)/len(test)\n",
    "\n",
    "    return Xdisagree, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aa0b2ace7df5181b0528208ca0cc0dcc",
     "grade": true,
     "grade_id": "cell-3b55f7e89ad4dfeb",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Xdisagree, probability = compare()\n",
    "assert type(Xdisagree) == list\n",
    "assert probability >= 0.0 and probability <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem of simple nearest neighbors is that one needs to compare the point to predict to all data points in the training set. This can be slow for datasets of thousands of points or more. Alternatively, some classifiers train a model first, and then use it to classify the data.\n",
    "\n",
    "## Nearest Mean Classifier: Trin and Predict methods\n",
    "\n",
    "We consider one such trainable model, which operates in two steps:compute the average point for each class and classify new points to be of the class whose average point is nearest to the point to predict. For this classifier, we use the modified distance function:\n",
    "\n",
    "`d(a,b) = (a[0] - b[0]) ** 2 + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] - b[2]) ** 2`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "303bfe831913b6c12d012e06b0815e0c",
     "grade": false,
     "grade_id": "cell-e0b339bfd0fcc16c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class NearestMeanClassifier:\n",
    "        \n",
    "    def train(self, dataset):\n",
    "        \n",
    "        # Define the base vector for \"more\", and count all \"more\"\n",
    "        self.vector_more = [0,0,0]\n",
    "        n_more = len([x for x in dataset if x[1] == \"more\"])\n",
    "        assert n_more != 0, \"Not enough target values\"\n",
    "\n",
    "        # Define the base vector for \"less\", and count all \"less\"\n",
    "        self.vector_less = [0,0,0]\n",
    "        n_less = len([x for x in dataset if x[1] == \"less\"])\n",
    "        assert n_less != 0, \"Not enough target values\"\n",
    "\n",
    "        for x in dataset:\n",
    "            \n",
    "            # Assign each value to a variable, for a future operations\n",
    "            smoker = x[0][0].lower()\n",
    "            age = x[0][1]\n",
    "            diet = x[0][2].lower()\n",
    "            risk = x[1].lower()\n",
    "\n",
    "            # Transformation to True (==1) or False (==0)\n",
    "            observation = (smoker == \"yes\", age, diet == \"poor\")\n",
    "\n",
    "            # Update the vectors\n",
    "            if risk == \"more\":\n",
    "                for i, value in enumerate(self.vector_more):\n",
    "                    # Compute average by sum of 1/n*Xi\n",
    "                    self.vector_more[i] += 1/n_more * observation[i]\n",
    "\n",
    "            if risk == \"less\":\n",
    "                for i, value in enumerate(self.vector_less):\n",
    "                    # Compute average by sum of 1/n*Xi\n",
    "                    self.vector_less[i] += 1/n_less * observation[i]\n",
    "\n",
    "        self.mean_vectors = {\n",
    "            \"more\": self.vector_more,\n",
    "            \"less\": self.vector_less\n",
    "        }\n",
    "        \n",
    "        return self.mean_vectors\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        # Define distance function\n",
    "        distance = lambda a,b: (a[0] - b[0]) ** 2 + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] - b[2]) ** 2\n",
    "        \n",
    "        # Transform the new vector\n",
    "        x = (x[0] == \"yes\", x[1], x[2] == \"poor\")\n",
    "        \n",
    "        # Find the distance\n",
    "        distance_to_more = distance(x, self.vector_more)\n",
    "        distance_to_less = distance(x, self.vector_less)\n",
    "        \n",
    "        if abs(distance_to_more) < abs(distance_to_less):\n",
    "            prediction = \"more\"\n",
    "        else:\n",
    "            prediction = \"less\"\n",
    "            \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an object of class `NearestMeanClassifier`, train it on the training data, and return the mean vector for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e41c5c9134feb3a505677bc939acc25d",
     "grade": false,
     "grade_id": "cell-5f7f00ee83c94703",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'more': [0.5714285714285714, 37.14285714285714, 0.5714285714285714],\n",
       " 'less': [0.3333333333333333, 32.111111111111114, 0.2222222222222222]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_and_train():\n",
    "\n",
    "    nmc = NearestMeanClassifier()\n",
    "    \n",
    "    return nmc.train(gettrain())\n",
    "    \n",
    "build_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "686cebaaedb7e41b87361a8408661ab1",
     "grade": true,
     "grade_id": "cell-415891bde4cbde19",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the test data using the nearest mean classifier and return all test examples for which all three classifiers (decision tree, nearest neighbor and nearest mean) agree. The algorithm returns a list containing tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "29945175006a71d97e57588c9c524df1",
     "grade": false,
     "grade_id": "cell-f37f3035a32a8f85",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('no', 50, 'good'), 'less'],\n",
       " [('no', 23, 'good'), 'less'],\n",
       " [('yes', 45, 'poor'), 'more'],\n",
       " [('no', 60, 'good'), 'less'],\n",
       " [('no', 15, 'poor'), 'more'],\n",
       " [('no', 18, 'good'), 'less']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_test():\n",
    "    \n",
    "    test = gettest()\n",
    "    train = gettrain()\n",
    "    \n",
    "    nmc = NearestMeanClassifier()\n",
    "    nmc.train(train)\n",
    "    \n",
    "    agreed_samples = list()\n",
    "    \n",
    "    for x in test:\n",
    "        \n",
    "        # Decision Tree\n",
    "        dt_pred = decision(x)\n",
    "        \n",
    "        # Nearest neighbor classifier\n",
    "        nnc_pred = neighbor(x,gettrain())\n",
    "\n",
    "        # NearestMeanClassifier: \n",
    "        nmc_pred = nmc.predict(x)\n",
    "\n",
    "        if dt_pred == nnc_pred == nmc_pred:\n",
    "            agreed_samples.append([x,dt_pred])\n",
    "\n",
    "            \n",
    "    return agreed_samples\n",
    "predict_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "951f7d822b4c3475ab6dc89fa3c87d46",
     "grade": true,
     "grade_id": "cell-853c957eaaf81c28",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
